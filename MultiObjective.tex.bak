\chapter{بهینه‌سازی چندهدفه}\label{MultiObjective}


در این فصل به بهینه‌سازی چندهدفه و روش‌های حل مدل‌های ریاضی چندهدفه می‌پردازیم. لازم به ذکر است، مطالب این فصل، عمدتاً از کتاب‌های ‎«‎بهینه‌سازی چندهدفه با استفاده از الگوریتم‌های تکاملی‎»\cite{DebBook}‎ نوشته کالیانموی دب ‎(2002)\LTRfootnote{Kalyanmoy Deb}‎ و کتاب ‎«‎الگوریتم‌های تکاملی برای حل مسائل چندهدفه‎»\cite{Coello}‎ نوشته کوئلو کوئلو  و همکاران ‎(2006)\LTRfootnote{Carlos A‎. ‎Coello Coello}‎، گرفته شده است. در این‌ فصل ابتدا، تعاریف و مفاهیم مربوط به بهینه‌سازی چندهدفه بیان خواهد شد؛ بعد از آن به بیان روش‌های برخورد با مسائل چندهدفه می‌پردازیم. 
‎\section{پیشگفتار}‎
بهینه‌سازی عبارت است از یافتن یک یا چند جواب موجه که مربوط به مقادیر بحرانی یک یا چند تابع هدف می‌باشند. منظور از یافتن چنین جواب‌های بهینه‌ای در یک مساله، اغلب به دست آوردن یک جواب جهت حداقل ساختن هزینه یا حداکثر کردن سود و یا غیره است. به همین دلیل، روش‌های بهینه‌سازی، اهمیت زیادی در حوزه‌های مهندسی و مدیریتی و تصمیم‌گیری‌های تجاری دارند. هنگامی که مساله بهینه‌سازی، تنها شامل یک تابع هدف باشد، عمل یافتن جواب بهینه، بهینه‌سازی تک هدفه‎\LTRfootnote{Single-Objective Optimization}‎ نامیده می‌شود. امروزه، روش‌ها و الگوریتم‌های بهینه‌سازی تک‌هدفه‌ای وجود دارند که با استفاده از فنون حستجوی گرادیان‎\LTRfootnote{Gradient}‎ و روش‌های ابتکاری عمل می‌کنند. 

هنگامی‌که یک مساله بهینه‌سازی شامل بیش از یک تابع هدف است، عمل یافتن یک یا چند جواب بهینه، بهینه‌سازی چندهدفه‎\LTRfootnote{Multi-Objective Optimization}‎ نامیده می‌شود. در ادبیات مدیریت، به این مسائل، تصمیم‌گیری چندمعیاره‎\LTRfootnote{Multiple Criterion Decision Making}‎ یا به اختصار ‎\lr{MCDM}‎ می‌گویند. از آنجا که بهینه‌سازی چندهدفه، شامل چندین هدف است، بهینه‌سازی تک‌هدفه، حالت خاصی از بهینه‌سازی چندهدفه می‌باشد. اغلب مسائل جستجو و بهینه‌سازی در دنیای واقعی، به طور ذاتی شامل چندین هدف می‌باشند که اکثراً این اهداف با یکدیگر متضاد هستند و برای به دست آوردن جواب بهینه، باید بین توابع هدف، بده-بستان‎\LTRfootnote{Trade-Off}‎ صورت گیرد. 

برای درک بهتر، به بررسی یک مساله تصمیم‌گیری می‌پردازیم که مربوط به خرید یک اتومبیل است. قیمت اتومبیل‌های در دسترس، در دامنه‌ای بین حدود ‎20‎ میلیون تومان تا ‎500‎ میلیون تومان قرار می‌گیرد. دو اتومبیل را به طور فرضی در دو سوی طیف در نظر می‌گیریم.  بدین معنی که، یکی با ارزش ‎25‎ میلیون تومان (جواب ‎1)‎ و دیگری با ارزش ‎450‎ میلیون تومان (جواب ‎2)‎ . اگر معبار هزینه، تنها هدف همه خریداران باشد، ما در جاده‌ها فقط یک نوع اتومبیل (جواب ‎1)‎ خواهیم دید و هیچ سازنده‌ای اتومبیل‌های گرانتری نخواهد ساخت. خوشبختانه این فرایند تصمیم‌گیری، یک فرایند تک‌هدفه نیست‎.\\‎ 
معمولاً انتظار می‌رود که یک ماشین ارزان، از راحتی کمتری برخوردار باشد. برای خریداران پولدار که ‎«راحتی»‎ تنها هدف تصمیم‌گیری آن‌هاست، انتخاب بهینه، جواب ‎2‎ است. بین این دو جواب حدی، جواب‌های زیاد دیگری نیز وجود دارد؛ برای مثال، یک خودرو با قیمت ‎70‎ میلیون تومان و راحتی بیشتر نسبت به جواب اول. بنابراین، از بین این دو جواب، برحسب هر یک از اهداف، یکی بهتر است، اما این بهتری با صرفنظر از هدف دیگر حاصل می‌شود. 

بهینه‌سازی چندهدفه، همچون بهینه‌سازی تک‌هدفه، به طور گسترده‌ای مورد مطالعه قرار گرفته است. الگوریتم‌ها و مطالعات کاربردی زیادی وجود دارند که شامل هدف‌های چندگانه هستند. به هر حال، در اغلب این مطالعات، مساله مشابهی وجود دارد؛ بیشتر این روش‌ها، از پیچیدگی‌های موجود در یک مساله بهینه‌سازی چندهدفه واقعی اجتناب می‌کنند و اهداف چندگانه را، با استفاده از یکسری پارامتر‌های تعریف شده توسط کاربر، به یک تابع هدف واحد تبدیل می‌نمایند. بنابراین، اغلب مطالعات بهینه‌سازی چندهدفه کلاسیک، برخورد متفاوتی با بهینه‌سازی چندهدفه نسبت به بهینه‌سازی تک‌هدفه، ندارند. اگرچه تئوری‌ها و الگوریتم‌های بهینه‌سازی تک‌هدفه، قابلیت کاربرد در جهت بهینه‌سازی تابع هدف تبدیل شده را، دارند؛ اما یک تفاوت بنیادی بین بهینه‌سازی تک‌هدفه و چندهدفه وجود دارد. این تفاوت را با بررسی مثال قبل بیان می‌کنیم؛ جواب‌های ‎1‎ و ‎2‎ هر کدام جواب بهینه یکی از اهداف هستند. اگر خریداری مایل به صرف هزینه‌ای بیشتر نسبت به جواب ‎1‎ باشد، احتمالاً اتومبیل دیگری را با سطح راحتی بهتری از این جواب، انتخاب می‌کند. یعنی مقدار هزینه اضافی صرف‌ شده، منجر به‏، به دست آوردن راحتی می‌شود. بنابراین، می‌توانیم مجموعه‌ای از جواب‌های بهینه را بین جواب ‎1‎ و جواب ‎2‎ تصور کنیم که بهبود در یک هدف مستلزم فداکردن هدف دیگر می‌باشد. 

حالا، سوال مهمی مطرح می‌شود: با این همه جواب‌های بده‌بستان در ذهن، شخص می‌تواند بگوید کدام جواب با در نظر گرفتن هر دو هدف بهترین است؟ دلیل آن در این حقیقت نهفته است که هیچ جوابی از این مجموعه که متشکل از هر دو هدف (هزینه و راحتی) است، نمی‌تواند بهتر از جواب دیگری از این مجموعه به نظر برسد. بنابراین در مسائلی با بیش از یک هدف متضاد، جواب بهینه واحدی وجود ندارد بلکه چندین جواب بهینه وجود دارد. بدون دانش بیشتری نمی‌توان گفت که کدام‌یک از اعضای مجموعه جواب‌های بهینه، از دیگری بهتر است. این همان تفاوت بنیادی بین بهینه‌سازی تک هدفه و چندهدفه است. جواب نهایی، در یک بهینه‌سازی تک‌هدفه، جواب واحدی است، در حالی که در بهینه‌سازی چندهدفه مجموعه‌ای از جواب‌های بهینه، که به دلیل بده‌بستان بین اهداف متضاد به وجود می‌آیند، با اهمیت هستند. 

گرچه تفاوت بنیادی بین بهینه‌سازی تک‌هدفه و چندهدفه، در اصل، در مجموعه جواب‌های بهینه است، اما از نقطه نظر عملی، یک کاربر صرفاً نیاز به یک جواب دارد و برای وی مهم نیست که مساله بهینه‌سازی مورد بررسی، تک‌هدفه یا چندهدفه باشد. در بهینه‌سازی چندهدفه، کاربر بر سر یک دوراهی است. کدام یک از این جواب‌های بهینه باید انتخاب گردد؟ در همان مثال مربوط به خرید خودرو، با آگاهی نسبت به تعداد جواب‌های موجود در بازار، با بده‌بستان‌های متفاوت بین هزینه و راحتی، کدام ماشین باید خریده شود؟ پاسخ این سوال آسان نیست؛ چراکه پاسخ به این سوال در برگیرنده ملاحظات بسیار دیگری نظیر کل دارایی در دسترس جهت خرید خودرو، مسافتی که باید هر روز پیموده شود، تعداد مسافرانی که سوار خودرو می‌شوند، مصرف و هزینه سوخت، میزان استهلاک، شرایط جاده‌ای و عوامل بسیارِ دیگری است. چنین اطلاعات سطح بالاتر، اغلب غیرفنی، کیفی و ناشی از تجربه است. به هر حال، اگر مجموعه‌ای از چندین جواب بده‌بستان تدوین گردد یا در دسترس باشد، شخص می‌تواند مزایا و معایب هر یک از این جواب‌ها را، مبتنی بر چنین ملاحظات غیرفنی و کیفی، مورد ارزیابی قرار داده و جهت انتخاب یک جواب، آن‌ها را مقایسه کند. بنابراین در یک بهینه‌سازی چندهدفه، به صورت ایده‌آل تلاش می‌شود تا مجموعه‌ای از جواب‌های بهینه، با در نظر گرفتن همه اهداف مهم، یافت شود. پس از یافتن مجموعه‌ای از چنین جواب‌های بده‌بستان، کاربر می‌تواند با استفاده از ملاحظات کیفی سطح بالاتر، دست به انتخاب بزند. کالیانموی دب ‎(2002)‎ یک فرایند بهینه‌سازی ایده‌آل را به صورت زیر پیشنهاد می‌کند‎.\\‎
گام ‎1‎: چندین جواب بده‌بستان، با دامنه گسترده‌ای از مقادیر برای اهداف پیدا کند‎.\\‎
گام ‎2‎: یکی از جواب‌‌های بهینه به دست آمده را با استفاده از اطلاعات سطح بالاتر انتخاب کند‎.\\‎
به این صورت که در گام اول چندین جواب بهینه بده‌بستان یافت می‌شود. پس از آن در گام ‎2‎ اطلاعات سطح بالاتر جهت انتخاب یکی از جواب‌های بده‌بستان، مورد استفاده قرار می‌گیرد.


به طور کلی برای حل مسائل بهینه‌سازی چندهدفه، دو رویکرد وجود دارد:
‎\begin{enumerate}‎
‎	\item‎ روش‌های بهینه‌سازی کلاسیک
‎	\item‎ روش‌های ایده‌آل (الگوریتم‌های تکاملی)
‎\end{enumerate}‎
نتیجه استفاده از یک روش بهینه‌سازی کلاسیک، یک جواب بهینه واحد است. در حالی که نتیجه استفاده از الگوریتم‌های تکاملی، مجموعه‌ای از جواب‌هاست که کاربر می‌تواند هر کدام را با توجه به شرایطش انتخاب کند. در بخش بعدی مفاهیم و مبانی بهینه‌سازی چندهدفه بیان خواهد شد و بعد از آن هر یک از روش‌های بهینه‌سازی کلاسیک و الگوریتم‌های تکاملی بیان خواهد شد. 


\section{مبانی بهینه‌سازی چندهدفه}
یک مساله بهینه‌سازی چندهدفه‎\LTRfootnote{Multi Objective Optimization Problem}‎ یا به اختصار ‎\lr{MOOP}‎، 
عبارت است از، تعدادی تابع هدف که باید کمینه یا پیشینه گردند. در اینجا همانند مساله بهینه‌سازی تک‌هدفه،‌ معمولاً مساله، محدودیت‌هایی دارد که هر جواب موجه (از جمله جواب‌های بهینه) باید آن‌ها را ارضا نماید. شکل عمومی مساله بهینه‌سازی چندهدفه به صورت زیر است:
‎\begin{align}‎
‎Max/Min \quad\quad   & f_{m}(x) \quad\quad &m=1,2,...,M \\ \nonumber‎
‎s.t\quad\quad & g_{1}(x) \geq 0  \quad\quad  &j=1,...,J \\ \nonumber‎
‎& h_{k}(x)=0 \quad\quad &k=1,...,K \\ \nonumber‎
‎& x_{i}^{L}\leq x_{i} \leq x_{i}^{U} \quad\quad &i=1,2,...n \\ \nonumber‎
‎\end{align}‎
جواب ‎\lr{x}‎ برداری از ‎\lr{n}‎ متغیر تصمیم می‌باشد: 
‎$X=(x_{1},x_{2},...,x_{n})^{T}$‎.
آخرین محدودیت، حدود متغیرها نامیده می‌شود که متغیر تصمیم را محدود به گرفتن مقداری بین یک حد پایینی
‎$x_{i}^{L}$‎
و یک حد بالایی 
‎$x_{i}^{U}$‎
می‌نماید. این یک فضای متغیر تصمیم یا به طور ساده‌تر فضای تصمیم را شکل می‌دهند. به صورت کلی در اینجا از اصطلاح ‎«نقطه»‎ یا ‎«جواب»‎ برای یک بردار جواب ‎\lr{x}‎ استفاده می‌کنیم. در مساله ‎\lr{J}‎ محدودیت نامعادله و ‎\lr{K}‎ محدودیت معادله وجود دارد. عبارات 
‎$g_{i}(x)$‎
و
‎$h_{k}(x)$‎ 
توابع محدودیت نامیده می‌شوند. در مساله بالا محدودیت نامعادله به صورت ‎«‎بزرگتر یا مساوی‎»‎ و ‎«‎کوچکتر مساوی‎»‎ به کار گرفته شده است. در مواردی که محدودیت‌ها به شکل ‎«‎کوچکتر مساوی‎»‎ هستند می‌توان آن‌ها را در  ‎$-1$‎
ضرب نمود و به ‎«‎بزرگتر مساوی‎»‎ تبدیل کرد. اگر یک جواب ‎\lr{x}‎ همه محدودیت‌ها و حدود متغیرها را برآورده سازد، به عنوان یک جواب موجه ‎(شدنی)‎ شناخته می‌شود و اگر جواب ‎\lr{x}‎ همه محدودیت‌ها را برآورده نسازد، به آن، جواب ناموجه ‎(نشدنی)‎ می‌گویند. مجموعه همه جواب‌های موجه، ‎«‎منطقه موجه‎»‎ نامیده می‌شود. 

در فرمولیشن بالا، ‎\lr{M}‎ تابع هدف به صورت
‎$f(x)=(f_{1}(x),f_{2}(x),...,f_{M}^{x})^{T}$‎
در نظر گرفته شده است. هر تابع هدف می‌تواند حداکثر یا حداقل شود. براساس اصل دوگان، در حوزه بهینه‌سازی، می‌توان یک مساله بیشینه‌سازی را، با ضرب کردن تابع هدفش در ‎$-1$‎ به یک مساله کمینه‌سازی تبدیل کرد. یکی از تفاوت‌های برجسته بین بهینه‌سازی تک‌هدفه و چندهدفه این است که در بهینه‌سازی چندهدفه، توابع هدف، علاوه بر یک فضای متغیر تصمیم معمول، یک فضای چندبعدی را به وجود می‌آورند. این فضای چندبعدی، فضای هدف ‎\lr{Z}‎ نامیده می‌شود. به ازای هر جواب ‎\lr{x}‎ در فضای متغیر تصمیم، نقطه‌ای در فضای هدف وجود دارد که با 
‎$f(x)=z=(z_{1},z_{2},...,z_{M})^{T}$‎
نشان داده می‌شود. در ادامه به تعریف دقیق اصطلاحات رایج در مساله بهینه‌سازی چندهدفه می‌پردازیم.
\begin{definition}[جواب‌های بهینه پارتو]
یک جواب ‎\lr{x}‎، عضو فضای موجه یا ‎\lr{S}‎ یک جواب بهینه پارتو نامیده می‌شود ، اگر و فقط اگر، هیچ جواب دیگری مانند ‎$x'\in S$‎ به طوری که ‎$V=F(x')=(f_{1}(x'),...,f_{m}(x'))$‎ مغلوب کند ‎$u=F(x)=(f_{1}(x),...,f_{m}(x))$‎ را، وجود نداشته باشد. 
‎\end{definition}‎
به عبارتی دیگر، 
‎$x^{*}$‎
یک جواب بهینه پارتو است اگر هیچ جواب شدنی دیگری مانند ‎\lr{x}‎ وجود نداشته باشد که یک هدف را کاهش دهد بدون اینکه همزمان یک هدف دیگر، افزایش نیابد (برای مساله حداقل سازی). مفهوم بهینگی پارتو با نظریه بهینه‌سازی چندهدفه ادغام شده است. چندین تعریف و اصطلاح دیگر نیز وجود دارد که در ادامه بیان خواهد شد. 
\subsection*{مفهوم غلبه}

اغلب الگوریتم‌های بهینه‌سازی چندهدفه از مفهوم غلبه استفاده می‌کنند. در این الگوریتم‌ها، دو جواب بر این اساس که یکی بر دیگری غالب است یا خیر، مورد مقایسه قرار می‌گیرند. در اینجا به توصیف مفهوم غلبه خواهیم پرداخت. 
فرض می‌کنیم ‎\lr{M}‎  تابع هدف وجود دارد. هم برای تابع هدف بیشینه و هم برای تابع هدف کمینه؛ از عمگر 
‎$\preceq$‎
بین دو جواب ‎\lr{i}‎ و ‎\lr{j}‎ 
،
به صورت 
‎$i\preceq j$‎
استفاده می‌کنیم. بدین معنی که جواب ‎\lr{i}‎ در هدف خاصی از جواب ‎\lr{j}‎  بهتر است. به طور مشابه، برای یک هدف خاص، 
‎$j\preceq i$‎
بدین معنی است که با توجه به این هدف، جواب ‎\lr{i}‎ از جواب ‎\lr{j}‎، 
بدتر است. برای مثال، اگر تابع هدفی، کمینه‌یابی باشد، عملگر 
‎$\preceq$‎
به معنای عملگر
‎$«<»$‎
است. همچنین اگر تابع هدف بیشینه‌سازی باشد، عملگر 
‎$\preceq$‎
به معنای عملگر 
‎$«>»$‎
است. تعریف زیر، مسائل مختلط با توابع هدف کمینه و بیشینه را پوشش می‌دهد. 

\begin{definition}[غلبه پارتو]
 بردار ‎$u=(u_{1},...,u_{m})$‎، بر بردار ‎$v=(v_{1},...,v_{m})$‎  غلبه می‌کند ‎($u\preceq v$)‎
	،اگر و فقط اگر ‎\lr{u}‎ کمتر از ‎\lr{v}‎ باشد(در یک مساله حداقل‌سازی)؛ به این صورت که، 
‎	$\forall i \in \{1,...,m\}‎, ‎u_{i}\leq v_{i} $‎ 
	و 
‎	$\exists i \in \{1,...,m\}‎: ‎u_{i}<v_{i}$‎
‎	\label{dom}‎
‎\end{definition}‎

در ادبیات بهینه‌سازی چندهدفه، اگر جواب 
‎$x_{1}$‎
بر جواب
‎$x_{2}$‎
غالب باشد، بدیهی است که جواب 
‎$x_{1}$‎
بهتر از 
‎$x_{2}$‎
است. از آنجا که مفهوم غلبه، زمینه مقایسه جواب‌ها با اهداف چندگانه را مهیا می‌سازد، اغلب روش‌های بهینه‌سازی چندهدفه از این مفهوم، برای جستجو جواب‌های نامغلوب استفاده می‌کنند. 
\begin{definition}[مجموعه نامغلوب]
	 از بین مجموعه جواب‌های ‎\lr{P}‎، 
	مجموعه جواب‌های نامغلوب
‎	$P'$‎
	، جواب‌هایی هستند که مغلوب هیچ یک از اعضای مجموعه 
‎	\lr{P}‎
	نیستند.
	در صورتی که مجموعه ‎\lr{P}‎، کل فضای جستجو باشد، یا 
‎	$P=S$‎
	، مجموعه نامغلوب 
‎	$P'$‎
	مجموعه بهینه‌ پارتو‎\LTRfootnote{Pareto-optimal set}‎ نامیده می‌شود. 
‎\end{definition}‎

در ادامه به روش‌های حل مساله بهینه‌سازی چندهدفه که به دو بخش روش‌های کلاسیک و الگوریتم‌های تکاملی تقسیم شده‌اند، می‌پردازیم. 

\section{روش‌های کلاسیک}
روش‌های کلاسیک بهینه‌سازی چندهدفه، دست کم در طول ‎6‎ دهه گذشته مطرح شده‌اند. در طول این دوره، الگوریتم‌های زیادی مطرح شده‌اند و پژوهشگران زیادی تلاش کرده‌اند تا این الگوریتم‌ها را مبتنی بر ملاحظات متنوعی تقسیم‌بندی کنند. معروف‌ترین این الگوریتم‌ها عبارتند از:
‎\begin{enumerate}‎
‎	\item‎ روش مجموع وزنی ‎\LTRfootnote{Weighted Sum method}‎
‎	\item‎ روش ‎$\epsilon$‎ محدودیت 
‎	\item‎ روش‌های وزنی متریک ‎\LTRfootnote{Weighted Metric Methods}‎
‎	\item‎ روش بنسون ‎\LTRfootnote{Benson's methods}‎
‎	\item‎ روش تابع ارزش ‎\LTRfootnote{Value function Method}‎
‎	\item‎ روش‌های برنامه‌ریزی آرمانی ‎\LTRfootnote{Goal Programming methods}‎
‎\end{enumerate}‎

که ما در اینجا روش‌های برنامه‌ریزی آرمانی را توضیح خواهیم داد.








































\subsection{روش برنامه‌ریزی آرمانی}
چارنز و کوپر‎\LTRfootnote{Charnes and Cooper}‎ و ایجری ‎\LTRfootnote{Ijiri}‎
روش برنامه‌ریزی آرمانی را برای یک مدل خطی توسعه داده و نقشی کلیدی در به کارگیری این روش در مسائل صنعتی داشتند. این روش، یکی از اولین روش‌هایی بود که به طور خاص برای مسائل چندهدفه توسعه داده شده است. در این روش، تصمیم‌گیرندگان باید اهداف یا آرمان‌هایی را که مایل هستند هر تابع هدف به آن دست پیدا کند را به هر یک از آن‌ها تخصیص دهند. این مقادیر به عنوان محدودیت‌های اضافی (محدودیت‌های آرمانی)، یک مساله جدید را تشکیل می‌دهند. سپس تابع هدف این مساله جدید، سعی می‌کند تا قدرمطلق ‎«‎انحراف توابع هدف از آرمان‎‌»‎ را حداقل کند. در واقع تفاوت بین ‎«‎محدودیت واقعی‎»‎ و ‎«‎محدودیت آرمانی‎»‎ این است که محدودیت واقعی، فضای متغیر تصمیم را به صورت مطلق کاهش می‌دهد؛ در حالی که، محدودیت‌های آرمانی، حدودی هستند که تمایل داریم به آن دست یابیم اما الزامی در برآورده شدن این محدوده‌ها نیست. فرمولیشن عمومی مدل برنامه‌ریزی آرمانی به صورت زیر است:
‎\begin{equation}‎
‎\label{multi:goal1}‎
‎\min Z= \sum_{m=1}^{M} (W_{m}^{+}* d_{m}^{+}‎ + ‎W_{m}^{-}*d_{m}^{-})‎
‎\end{equation}‎
‎\begin{equation}‎
‎\label{multi:goal2}‎
‎s.t‎: ‎\quad \quad f_{m}(x)‎ + ‎d_{m}^{-}‎ + ‎d_{m}^{+} = b_{m} \quad\quad m=1,...,M‎
‎\end{equation}‎
‎\begin{equation}‎
‎\label{multi:goal3}‎
‎g_{j}(x) \geq 0 \quad\quad j=1,...,J‎
‎\end{equation}‎
‎\begin{equation}‎
‎\label{multi:goal4}‎
‎h_{k}(x) = 0 \quad\quad k=1,...,K‎
‎\end{equation}‎
‎\begin{equation}‎
‎\label{muti:goal5}‎
‎x_{i}‎, ‎d_{m}^{-}‎ , ‎d_{m}^{+} \geq 0 \quad\quad \forall m,i‎
‎\end{equation}‎

معادله ‎\ref{multi:goal1}‎
نشان‌دهنده‌ی تابع هدف مدل برنامه‌ریزی آرمانی می‌باشد که مجموع وزنی متغیر‌های انحراف را حداقل می‌کند. معادله 
‎\ref{multi:goal2}‎
نشان‌دهنده‌ی محدودیت‌های آرمانی مربوط به معیار‌های مختلف و آرمان‌های متناظر آن‌ها می‌باشد. معادلات 
‎\ref{multi:goal3}‎ 
و 
‎\ref{multi:goal4}‎
نشان‌دهنده‌ی محدودیت‌های واقعی مدل می‌باشد. متغیر‌های 
‎$d_{i}^{+}‎, ‎d_{i}^{-}$‎
در معادله 
‎\ref{muti:goal5}‎
، نشان‌دهنده‌ی ‎«‎انحراف بیشتر‎»‎ و ‎«‎انحراف کمتر‎»‎ از ‎\lr{i}‎امین آرمان است. 
مجموعه وزن‌های 
‎$W_{i}^{+}‎, ‎W_{i}^{-}$‎
از دو طریق زیر تعیین می‌شوند:
‎\begin{enumerate}‎
‎	\item‎ وزن‌های از پیش تعیین شده
‎	(\lr{Cardinal})‎
‎	\item‎   اولویت‌های ترتیبی
‎	(\lr{Ordinal})‎
‎\end{enumerate}‎
در روش اول، تصمیم‌گیرندگان
‎\LTRfootnote{Decision Makers}‎
با بده‌بستان میان آرمان‌ها، مقادیر عددی مشخصی را در مقیاس معین، به وزن‌های 
‎$W_{i}^{+}‎, ‎W_{i}^{-}$‎
تخصیص می‌دهند. 
اما در روش دوم که وزن‌ها به صورت 
‎\lr{Ordinal}‎
تعیین می‌شوند، تصمیم‌گیرندگان، این وزن‌ها را به صورت ناسازگار و در مقیاس متفاوت، نسبت به هم تعیین می‌شوند، که نشان‌دهنده‌ی اولویت آرمان‌ها نسبت به هم باشند. 

راویندران و همکاران ‎(2010)‎ مدل‌های برنامه‌ریزی آرمانی را به چهار دسته تقسیم کرده‌اند که در ادامه برای مدل 
‎\ref{models:m2}‎
آن‌ها را بیان می‌کنیم.

\subsubsection*{برنامه‌ریزی آرمانی ‎\lr{Preemptive}}‎
برای سه معیار مساله ‎\ref{models:m2}‎
، فرمولیشن برنامه‌ریزی آرمانی ترتیبی به صورت زیر است:
‎\begin{equation}‎
‎\min P_{1}*d_{1}^{+}‎ + ‎P_{2}*d_{2}^{+}‎ + ‎P_{3}*d_{3}^{+}‎
‎\end{equation}‎
محدودیت‌ها:
‎\begin{equation}‎
‎\label{multi:pre1}‎
‎\sum_{j}\sum_{k} P_{jk}.X_{jk}‎ + ‎\sum_{j} F_{j}.f_{j}‎ - ‎\sum_{j}\sum_{k} P_{jk}‎. ‎K_{jk}‎. ‎S_{j}‎ + ‎d_{1}^{-}‎ - ‎d_{1}^{+} = \text{آرمان قیمت}
‎\end{equation}‎
‎\begin{equation}‎
‎\sum_{j}\sum_{k} VaR_{j}‎. ‎X_{jk}‎ + ‎d_{2}^{-}‎ - ‎d_{2}^{+} = \text{آرمان مربوط به ‎\lr{VaR}}‎
‎\end{equation}‎
‎\begin{equation}‎
‎\sum_{j}\sum_{k} MtT_{j}.X_{jk}‎ + ‎d_{3}^{-}‎ - ‎d_{3}^{+} = \text{آرمان مربوط به ‎\lr{MtT}}‎
‎\end{equation}‎
‎\begin{equation}‎
‎d_{m}^{-}‎ , ‎d_{m}^{+} \geq 0 \quad \forall m \in \{1,2,3\}‎
‎\end{equation}‎
‎\begin{equation}‎
‎X_{jk} \leq Cap_{jk}.f_{k} \quad \forall j,k‎
‎‎\label{multi:pre}‎‎
‎\end{equation}‎
‎\begin{equation}‎
‎\sum_{j} X_{jk} = D_{k} \quad \forall k‎
‎\end{equation}‎
‎\begin{equation}‎
‎\sum_{j} f_{j} \geq N‎
‎\end{equation}‎
‎\begin{equation}‎
‎B_{jk}.S_{j}‎ - ‎X_{jk} \geq 0 \quad \forall j,k‎
‎\end{equation}‎
‎\begin{equation}‎
‎\label{multi:pre8}‎
‎S_{j} \in \{0,1\} \quad‎ , ‎f_{j} \in \{0,1\} \quad‎ , ‎X_{j,k} \geq 0‎
‎\end{equation}‎

در این روش، تصمیم‌گیرندگان ترجیحات خود برای آرمان‌ها را بدون هیچ وزنی، ارائه می‌کنند. به این صورت که در این مدل برای تصمیم‌گیرندگان ابتدا آرمان قیمت مهم است و در اولویت بعدی، آرمان مربوط به ‎\lr{VaR}‎
و در اولویت آخر، آرمان مربوط به ‎\lr{MtT}‎
اهمیت دارد. همچنین مقادیر مربوط به هر آرمان توسط تصمیم‌گیرندگان تعیین می‌شود.

متغیر‌های 
‎$d_{1}^{-}‎, ‎d_{2}^{-}‎ , ‎d_{1}^{+}‎, ‎d_{2}^{+}$‎
، متغیر‌های انحراف هستند که نشان‌ می‌دهند که چه مقدار از هر آرمان فاصله داریم. نمادهای 
‎$P_{1}‎, ‎P_{2}‎, ‎P_{3}$‎
، اولویت‌های ترتیبی هستند که ترتیب حل آرمان‌ها را مشخص می‌کند. آرمان با اولویت بالاتر، اول از همه برآورده خواهد شد (که این‌جا، آرمان قیمت است) و بعد از آن، آرمان با اولویت کمتر (که در اینجا آرمان ‎\lr{VaR}‎‎ است)
و بعد از آن آرمان با کمترین اولویت (که در اینجا آرمان ‎\lr{MtT}‎ است). بنابراین در اینجا ابتدا 
‎$P_{1}$‎
، متغیر 
‎$d_{1}^{+}$‎
را مجبور می‌کند تا کمترین مقدار را به خود بگیرد، سپس ‎$P_{2}$‎
حل می‌شود و سعی می‌کند که 
‎$d_{2}^{+}$‎
را حداقل کند، در حالی که مقدار 
‎$d_{1}^{+}$‎
را برابر با حداقل مقدار به دست آمده از 
‎$P_{1}$‎
قرار می‌دهیم. به همین صورت، 
‎$P_{3}$‎
حل می‌شود و تلاش می‌کند تا مقدار 
‎$d_{3}^{+}$‎
را حداقل کند، در حالی‌که 
‎$d_{1}^{+}‎, ‎d_{2}^{+}$‎
را برابر با مقادیری که 
‎$P_{1},P_{2}$‎
به دست آمده‌اند، قرار می‌دهیم. در واقع این روش، شامل حل یک سری از مسائل بهینه‌سازی است. 

\subsubsection*{برنامه‌ریزی آرمانی ‎\lr{Non-Preemptive}}‎
در مدل برنامه‌ریزی آرمانی ‎\lr{Non-Preemptive}‎
تصمیم‌گیرندگان، آرمان‌های مطلوب برای هر هدف و همچنین، ترجیحات و اولویت‌ها در دستیابی به این آرمان‌ها را به صورت وزن‌های عددی تعیین می‌کند. 
مدل برنامه‌ریزی آرمانی ‎\lr{Non-Preemptive}‎
برای مدل 
‎\ref{models:m2}‎
به صورت زیر می‌باشد:
‎\begin{equation}‎
‎\min Z = W_{1}*d_{1}^{+}‎ + ‎W_{2}* d_{2}^{+}‎ + ‎W_{3}* d_{3}^{+}‎
‎\end{equation}‎
و محدودیت‌های 
‎\ref{multi:pre1}‎
تا 
‎\ref{multi:pre8}‎
نیز شامل این مدل هستند.
در این روش به خاطر استفاده از وزن‌های عددی، آرمان‌ها باید به صورت مناسب، هم‌مقیاس شده باشند. 

\subsubsection*{برنامه‌ریزی آرمانی ‎\lr{Min-Max}}‎
در این مدل برنامه‌ریزی آرمانی، تصمیم‌گیرندگان فقط مقادیر آرمان‌ها را برای هر تابع هدف تعیین می‌کنند.
در این روش، حداکثر انحراف از آرمان‌های مشخص شده حداقل می‌شود. برای مدل
‎\ref{models:m2}‎
برنامه‌ریزی‌ آرمانی ‎\lr{Min-Max}‎
به صورت زیر می‌باشد:
‎\begin{equation}‎
‎\label{multi:minmax}‎
‎\min-\max(W_{1}*d_{1}^{+}‎ , ‎W_{2}*d_{2}^{+}‎ , ‎W_{3}*d_{3}^{+})‎
‎\end{equation}‎

که 
‎$W_{1}‎, ‎W_{2}‎, ‎W_{3}$‎
، وزن‌هایی هستند که توسط تصمیم‌گیرندگان به صورت عددی تعیین شده‌اند (مانند روش ‎\lr{Non-Preemptive})‎

تابع هدف شماره 
‎\ref{multi:minmax}‎
، خطی نیست اما می‌توان آن را به صورت یک تابع خطی نوشت، به این صورت که :
‎\begin{equation}‎
‎\max (W_{1}*d_{1}^{+}‎ , ‎W_{2}*d_{2}^{+}‎, ‎W_{3}*d_{3}^{+}) = M‎
‎\end{equation}‎
که 
‎$M \geq 0$‎
. بنابراین، مدل برنامه‌ریزی آرمانی ‎\lr{Min-Max}‎
به صورت زیر بازنویسی می‌شود:
‎\begin{equation}‎
‎\min Z = M‎
‎\end{equation}‎
محدودیت‌ها:
‎\begin{equation}‎
‎M \geq (W_{1}*d_{1}^{+})‎
‎\end{equation}‎
‎\begin{equation}‎
‎M \geq (W_{2}*d_{2}^{+})‎
‎\end{equation}‎
‎\begin{equation}‎
‎M \geq (W_{3}*d_{3}^{+})‎
‎\end{equation}‎

و محدودیت‌های 
‎\ref{multi:pre1}‎
تا 
‎\ref{multi:pre8}‎
نیز شامل این مدل هستند.

\subsubsection*{مدل برنامه‌ریزی آرمانی فازی ‎\LTRfootnote{Fuzzy Goal Programming}}‎
مدل برنامه‌ریزی آرمانی فازی از مقادیر ایده‌آل‎\LTRfootnote{Ideal Solution}‎
به عنوان آرمان استفاده می‌کند و حداکثر فاصله نرمالایز شده از مقادیر ایده‌آل  را برای هر تابع هدف حداقل می‌کند. یک بردار ایده‌آل برداری است از بهترین جواب‌هایی که به وسیله بهینه‌سازی برای هر تابع هدف به صورت مستقل (از توابع هدف دیگر) به دست آمده است. 
اگر 
‎$M$‎
برابر با ماکزیمم انحراف از مقادیر ایده‌آل باشد، سپس مدل برنامه‌ریزی آرمانی فازی برای مدل
‎\ref{models:m2}‎
، به صورت زیر به دست می‌آید:
‎\begin{equation}‎
‎\min Z = M‎
‎\end{equation}‎
محدودیت‌ها:
‎\begin{equation}‎
‎M \geq W_{1} \big(\frac{z_{1}-z_{1}^{*}}{z_{1}^{*}} \big)‎
‎\end{equation}‎
‎\begin{equation}‎
‎M \geq W_{2} \big(\frac{z_{2}-z_{2}^{*}}{z_{2}^{*}} \big)‎
‎\end{equation}‎
‎\begin{equation}‎
‎M \geq W_{3} \big(\frac{z_{3}-z_{3}^{*}}{z_{3}^{*}} \big)‎
‎\end{equation}‎
و محدودیت‌های 
‎\ref{multi:pre}‎
تا 
‎\ref{multi:pre8}‎
نیز شامل این مدل هستند.

نماد‌های
‎$z_{1}^{+},z_{2}^{+},z_{3}^{+}$‎
در فرمولیشن بالا، نشان‌دهنده‌ی مقدار بهینه هر تابع هدف است که به صورت مستقل به دست آمده است. مقادیر 
‎$W_{1},W_{2},W_{3}$‎
وزن‌هایی هستند که توسط تصمیم‌گیرندگان به صورت عددی تعیین می‌شوند. 

ما در این پایان نامه از روش برنامه‌ریزی آرمانی فازی، برای حل مدل‌ها استفاده کرده‌ایم.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{الگوریتم‌های تکاملی}
الگوریتم‌های تکاملی در ایجاد رویه‌های جستجو و بهینه‌سازی، از اصول تکامل طبیعی تقلید می‌نمایند. الگوریتم‌های تکاملی از جنبه‌های مختلفی با رویه‌های جستجو و بهینه‌سازی متفاوت‌اند. در اینجا تعدادی از الگوریتم‌های تکاملی را نام برده و الگوریتم ژنتیک مرتب‌سازی نامغلوب نسخه دوم ‎(\lr{NSGA-2})‎  
به صورت کامل معرفی خواهد شد. الگوریتم‌های تکاملی، که برای  حل مسائل بهینه‌سازی استفاده می‌شوند به ترتیب تاریخ ارائه، عبارتنداز:

‎\begin{itemize}‎
‎	\item‎ الگوریتم ژنتیک ارزیابی‌شده برداری‎(\lr{VEGA}) \LTRfootnote{Vector Evaluated GA}‎
‎	\item‎ الگوریتم ژنتیک ترتیبی لکسیکوگرافیک‎\LTRfootnote{Lexicographic Ordering GA}‎
‎	\item‎ الگوریتم استراتژی تکاملی بهینه‌سازی برداری‎(\lr{VOES})\LTRfootnote{Vector Optimized Evolution Strategy}‎
‎	\item‎ الگوریتم ژنتیک بر مبنای وزن‌دهی‎(WBGA)\LTRfootnote{Weight-Based GA}‎
‎	\item‎ الگوریتم ژنتیک چندهدفه ‎(\lr{MOGA}) \LTRfootnote{Multiple Objective GA}‎
‎	\item‎ الگوریتم ژنتیک پارتو خردشده ‎(\lr{NPGA,NPGA2}) \LTRfootnote{Niched Pareto GA}‎
‎	\item‎ الگوریتم ژنتیک مرتب‌‌سازی نامغلوب‎(\lr{NSGA,NSGA2}) \LTRfootnote{Nondominated Sorting GA}‎
‎	\item‎ الگوریتم ژنتیک پارتو بر مبنای فاصله ‎(\lr{DPGA}) \LTRfootnote{Distance-based Pareto GA}‎
‎	\item‎ الگوریتم ژنتیک ترمودینامیکال ‎(\lr{TDGA}) \LTRfootnote{Thermodynamical GA}‎
‎	\item‎ الگوریتم تکاملی پارتو قوی ‎(\lr{SPEA,SPEA2}) \LTRfootnote{Strength Pareto Evolutionary Algorithm}‎
‎	\item‎ الگوریتم زنتیک چندهدفه بی‌نظم ‎(\lr{MOMGA}) \LTRfootnote{Multi-Objective Messy}‎  
‎\end{itemize}‎



\subsection*{الگوریتم ژنتیک}
الگوریتم ژنتیک، از معروفترین الگوریتم‌های تکاملی است. به طوری‌که هروقت صحبت از الگوریتم‌های تکاملی و فراابتکاری می‌شود، الگوریتم ژنتیک به عنوان مصداقی مهم شناخته می‌شود. الگوریتم ژنتیک نوع خاصی از الگوریتم‌های تکاملی است که از تکنیک‌های زیست‌شناسی تکاملی مانند انتخاب طبیعی ‎(\lr{Natural Selection})‎ ؛ تولید مثل ‎(\lr{Reproduction})‎ ؛ جهش ‎(\lr{Mutation})‎ ؛ همزیستی ‎(\lr{Symbiosis})‎
و همچنین اصول انتخابی داروین برای یافتن جواب بهینه در مسائل مختلف استفاده می‌کند. 

یک الگوریتم تکاملی از چند مرحله ساده زیر تشکیل شده است:
‎\begin{enumerate}‎
‎	\item \textbf{ایجاد}‎ مجموعه‌ای از جواب‌های تصادفی
‎	\item \textbf{مقایسه}‎ جواب‌ها و ‎\textbf{رتبه‌بندی}‎ آن‌ها و ‎\textbf{انتخاب}‎ بهترین‌ها  
‎	\item \textbf{ترکیب}‎ جواب‌های به دست آمده، با شبیه‌سازی فرایندهای طبیعی مانند تولید مثل و ادغام جواب‌های جدید 
‎	\item‎ بازگشت به مرحله ‎2 (در صورت نیاز)
‎\end{enumerate}‎

از اوایل دهه ‎1950‎ میلادی، تلاش‌هایی برای شبیه‌سازی پدیده تکامل بر روی کامپیوتر‌ها آغاز شد، که در این میان توجه بسیاری از محققین حوزه‌های مربوط به علوم ریاضی و مهندسی، به این زمینه جلب شد. نهایتا در اوایل دهه ‎1970‎، جان هالند
‎\LTRfootnote{John Holland}‎
، در کتابش، الگوریتم ژنتیک را به عنوان ابزاری عمومی برای بهینه‌سازی معرفی نمود. 
یکی از شاگردان هالند، به نام دیوید گولدبرگ
‎\LTRfootnote{David E‎. ‎Goldberg}‎
، کار‌های پراکنده‌ای را که توسط هالند انجام شده بود را، جمع‌آوری کرد و به همراه نتایج حاصل از تحقیقات خود، در قالب یک کتاب جامع منتشر نمود. می‌توان گفت گولدبرگ با انتشار این کتاب بیشترین سهم را در توسعه معرفی الگوریتم ژنتیک داشته‌ است.
مراحل الگوریتم ژنتیک به صورت زیر است:
‎\begin{enumerate}‎
‎	\item‎ ایجاد جمعیت تصادفی و ارزیابی آن‌ها
‎	\item‎ انتخاب والدین و ترکیب ‎(\lr{CrossOver})‎ آن‌ها برای ایجاد جمعیت فرزندان
‎	\item‎ انتخاب اعضای جمعیت برای اعمال جهش ‎(\lr{Mutation})‎ و ایجاد جمعیت جهش‌یافتگان
‎	\item‎ ادغام جمعیت اصلی، فرزندان و جهش‌یافتگان و ایجاد جمعیت اصلی جدید
‎	\item‎ اگر شرایط خاتمه محقق نشده باشند، از مرحله ‎2‎، تکرار می‌کنیم.
‎	\item‎ پایان
‎\end{enumerate}‎
الگوریتم ژنتیک یک جمعیتی از نقاط را نگه داری می‌کند که با 
‎$P(t)$‎
برای نسل 
‎\lr{t}‎
نشان داده می‌شود. هر نقطه نشان‌دهنده‌ی یک جواب بالقوه برای مساله مورد نظر می‌باشد. هر نقطه از این جمعیت به وسیله تابع هدف، ارزیابی می‌شود. بعضی از این نقاط توسط عملگر‌های ژنتیک 
به نقاطی جدید تبدیل می‌شوند. 
دو نوع تبدیل وجود دارد: اولین تبدیل،
‎\textbf{جهش}\LTRfootnote{Mutation}‎
می‌باشد
که نقاط جدید را به وسیله تغییر در یک نقطه، ایجاد می‌کند، دومین تبدیل، 
‎\textbf{تقاطع}\LTRfootnote{CrossOver}‎
می‌باشد که نقاط جدید را به وسیله ترکیب بخش‌هایی از دو نقطه، ایجاد می‌کند. 
نقاط جدید، فرزندان
‎\LTRfootnote{Offspring}‎
.نامیده می‌شوند
این نقاط نیز باید مورد ارزیابی قرار بگیرند. جمعیت جدید با انتخاب بخشی از 
جمعیت والد و بخشی از جمعیت فرزندان، شکل می‌گیرد. 












انواع شرایط خاتمه می‌تواند: رسیدن به حد قابل قبولی از پاسخ؛ سپری شدن زمان/ تکرار معین؛ سپری شدن زمان/ تعداد تکرار معین، بدون مشاهده بهبود خاصی در نتیجه، باشد. 
\subsubsection*{عملگر انتخاب (تکثیر یا تولید مثل) ‎\LTRfootnote{Reproduction or Selection}}‎
براساس نظریه حیات، بهترین موارد باید انتخاب شوند تا نسل بعدی بهتری ایجاد کنند؛ به همین دلیل، گاه به عملگر تولید مثل،‌ عملگر انتخاب هم گفته می‌شود. این عملگر مشابه انتخاب طبیعی است، به نحوی که فقط متناسب‌ترین کروموزوم‌ها در جمعیت زنده می‌مانند تا به نسل بعدی منتقل شوند؛ همچنین این عملگر از انتقال کروموزوم‌های بد به نسل بعد جلوگیری می‌کند. ممکن است عوامل مختلفی به منظور انتخاب کروموزوم‌های والد تعریف شوند، اما به طور معمول از تابع برازندگی (تابع هدف) برای این منظور استفاده می‌شود. 

هدف اصلی عملگر انتخاب، مضاعف ساختن جواب‌های خوب و حذف جواب‌های بد در یک جمعیت است، در حالی‌که اندازه جمعیت ثابت باقی بماند. این امر با اجرای مراحل زیر قابل دستیابی است:
‎\begin{enumerate}‎
‎	\item‎ مشخص کردن جواب‌های خوب در یک جمعیت
‎	\item‎ ایجاد چندین کپی از هر جواب خوب
‎	\item‎ حذف جواب‌های بد از جمعیت، آن‌چنان‌که نمونه‌های ایجاد شده از جواب‌های خوب بتوانند جایگزین آن‌ها در جمعیت شوند
‎\end{enumerate}‎
جهت اجرای مراحل فوق، راه‌های متعددی وجود دارد. تعدادی از روش‌های رایج عبارت‌اند‌از: انتخاب مسابقه‌ای ‎\LTRfootnote{Tournament selection}‎، انتخاب متناسب ‎\LTRfootnote{Proportionate selection}‎
و غیره. ‎\\‎

در انتخاب مسابقه‌ای، مسابقه‌ای بین هر دو جواب اجرا شده و بهترین جواب انتخاب می‌شود، از نو دو جواب دیگر انتخاب شده و بهترین آن‌ها، انتخاب می‌شود، در صورتی‌که این رویه به طور منظم صورت گیرد، هر جواب دقیقا در دو مسابقه شرکت می‌کند. بهترین جواب در جمعیت جوابی است که دو بار برنده شود و از این رو دو کپی از آن در جمعیت جدید ایجاد می‌گردد. با استدلال مشابه، بدترین جواب، جوابی است که در هر دو مسابقه بازنده است، بنابراین از جمعیت حذف می‌گردد. بدین ترتیب، هر جوابی از جمعیت، صفر، یک یا دو کپی در جمعیت خواهد داشت. ثابت شده است که انتخاب مسابقه‌ای، نسبت به دیگر عملگرهای انتخاب، دارای زمان محاسباتی کمتری است.
‎\\‎




\textbf{انتخاب متناسب‎:}‎
در روش انتخاب متناسب، تعدادی کپی از جواب‌ها ساخته می‌شود که آن تعداد برای هر جواب متناسب با مقدار برازش (مقدار تابع هدف) آن است. اگر میانگین برازش همه عناصر جمعیت 
‎$f_{avg}$‎
باشد، برای جوابی با مقدار برازش 
‎$f_{i}$‎
انتظار می‌رود که به تعداد 
‎$\frac{f_{i}}{f_{avg}}$‎
کپی ایجاد گردد. این عملگر انتخاب را می‌توان همچون مکانیزم یک چرخ رولت در نظر گرفت که در آن چرخ به ‎\lr{N}‎
قسمت
(اندازه جمعیت) تقسیم شده است و اندازه هر قسمت متناسب با مقدار برازش هر یک از عناصر جمعیت است. چرخ را ‎\lr{N}‎
بار چرخانده و در هر بار، جوابی را که نشانگر انتخاب
‎($\blacktriangle$)‎
در شکل 
‎\ref{Line}‎
نشان می‌دهد، انتخاب می‌کنیم. از آن‌جا که سومین قسمت،‌ مقدار برازش بیشتری نسبت به سایر جواب‌ها دارد، انتظار می‌رود که انتخاب چرخ رولت ‎(\lr{RWS})‎
بیشتر از سایر جواب‌ها به جواب سوم منجر شود. ‎\\‎
با استفاده از مقدار برازش 
‎$F_{i}$‎
برای همه رشته‌ها، احتمال انتخاب ‎\lr{i}‎
امین رشته به صورت 
‎$P_{i}=\frac{F_{i}}{\sum_{j=1}^{N}}$‎
به دست می‌آید. همچنین احتمال تجمعی هر رشته را می‌توان به صورت 
‎$P_{i}=\sum_{j=1}^{i} p_{j}$‎
(مجموع احتمالات جواب‌های قبل) محاسبه نمود. بنابراین احتمال تجمعی پایین‌ترین رشته
‎$(P_{N})$‎
برابر با یک می‌باشد. ‎\\‎
مفهوم چرخ رولت را می‌توان با درک این مطلب که 
‎\lr{i}‎
امین رشته در جمعیت، نمایانگر مقدار احتمال تجمعی در دامنه
‎$[P_{i-1}‎ ,  ‎P_{i}]$‎
است، شبیه‌سازی نمود. اولین رشته نمایانگر مقادیر تجمعی از صفر تا
‎$p_{1}$‎
است. به منظور انتخاب 
‎\lr{N}‎
رشته، ‎\lr{N}‎
عدد تصادفی بین صفر تا یک ایجاد می‌گردد. سپس از رشته‌ای که نمایانگر عدد تصادفی انتخاب شده در دامنه احتمال تجمعی است، نمونه مورد نظر را انتخاب می‌کنیم. شکل
‎\ref{Line}‎
،
خط احتمال تجمعی (که دامنه آن از صفر تا یک است) و دامنه‌های متناظر با هر یک از پنج جواب مساله،‌مثالی که در شکل 
‎\ref{RW}‎
نشان‌داده شده را نشان می‌دهد. 
عدد تصادفی 
‎$r_{i}$‎
که با علامت 
‎$\blacktriangle$‎
نشان داده شده است، نشانگر جواب ‎3‎ است. بنابراین جواب ‎3‎ به عنوان یکی از اعضای استخر جفت‌گیری انتخاب می‌کنیم. ‎\\‎
بدین ترتیب، رشته‌ای با مقدار برازش بالاتر،‌ نمایانگر دامنه بزرگتری از مقادیر احتمال تجمعی بوده و از اینرو احتمال انتخاب شدن آن بیشتر است. از آن‌جا که لازمه محاسبه میانگین برازش، داشتن مقدار برازش همه عناصر جمعیت است، این عملگر انتخاب در مقایسه با روش انتخاب مسابقه‌ای کندتر است.
‎\begin{figure}‎
‎	\begin{center}‎
	‎	\includegraphics[scale=1]{RoletteWheel2.png}‎
‎	\end{center}‎
	\caption{یک اجرای عملگر انتخاب چرخ رولت}
‎	\label{Line}‎
‎\end{figure}‎

‎\begin{figure}‎
‎	\begin{center}‎
	‎	\begin{subfigure}‎
	‎		\centering‎
	‎		\includegraphics[scale=.5]{RouletteWheelPic.png}‎
	‎	\end{subfigure}‎
	‎	\quad‎
	‎	\begin{subfigure}‎
	‎		\centering‎
	‎		\includegraphics[scale=.8]{RouletteExample.pdf}‎
	‎	\end{subfigure}‎
‎	\end{center}‎
	\caption{چرخ به ‎5‎ قسمت مجزا متناسب با مقادیر برازش تقسیم شده است. احتمال انتخاب قسمت سوم از سایر قسمت بیشتر است}
‎	\label{RW}‎
‎\end{figure}‎



\subsubsection*{عملگر تقاطع}
اساسی‌ترین عملگر در تولید جمعیت جدید در الگوریتم ژنتیک، عملکرد تقاطع است. در این عملگر، اطلاعات در طول رشته‌های موجود، معاوضه می‌شوند تا رشته‌های جدید را شکل دهند. به عبارت دیگر، فرایند تقاطع خصوصیت‌های جدیدی را می‌سازد که خصوصیت‌های ژنتیکی را دارا هستند. از این عملگر انتظار می‌رود که زیررشته‌های خوبی را از والدین انتخاب کند تا پس از ترکیب، بهترین فرزندان حاصل شوند. 
سه نوع تقاطع در این الگوریتم موجود است:
‎\begin{enumerate}‎
‎	\item‎ تقاطع تک‌نقطه‌ای‎\LTRfootnote{Single Point Crossover}‎
‎	\item‎ تقاطع چند‌نقطه‌ای ‎\LTRfootnote{Double Point Crossover}‎
‎	\item‎ تقاطع یکنواخت ‎\LTRfootnote{Uniform Crossover}‎
‎\end{enumerate}‎
تقاطع تک نقطه‌ای: در تقاطع تک‌نقطه‌ای دو رشته منحصر به فرد از جمعیت به صورت تصادفی انتخاب می‌شوند. سپس یک محل برای برش به صورت تصادفی در طول رشته انتخاب می‌شود و رقم‌های باینری یا ژن‌های ناهمسو مجاور، در محل برش بین دو رشته مورد نظر مبادله می‌شود. شکل 
‎\ref{single}‎
تقاطع تک‌نقطه‌ای را نشان می‌دهد. 
‎\begin{figure}‎
‎	\begin{center}‎
	‎	\includegraphics[scale=1]{singlepointcrossover.pdf}‎
‎	\end{center}‎
	\caption{تقاطع تک نقطه‌ای}
‎	\label{single}‎
‎\end{figure}‎
‎\\‎
تقاطع دو نقطه‌ای: در تقاطع دونقطه‌ای برای ایجاد برش در طول رشته‌ها، دو محل برش را به صورت تصادفی و بدون تکرار انتخاب می‌کنیم و رقم‌های باینری را در محل‌های برش، بین دو برش مبادله می‌کنیم.
شکل 
‎\ref{double}‎
تقاطع دونقطه‌ای را نشان می‌دهد. 
‎\begin{figure}‎
‎	\begin{center}‎
	‎	\includegraphics[scale=1]{doublepointcrossover.pdf}‎
‎	\end{center}‎
	\caption{تقاطع دو نقطه‌ای}
‎	\label{double}‎
‎\end{figure}‎
‎\\‎
تقاطع یکنواخت: در روش‌های برش تک‌نقطه‌ای و چند‌نقطه‌ای، محل‌هایی در طول رشته‌های موجود تعیین می‌شوند که در آن موقعیت‌های رشته‌ها قادر به جدا شدن و شکسته شدن هستند، ولی روش برش یکنواخت، این برنامه و طرح را عمومیت می‌بخشد، تا هر مکانی در رشته، قابلیت نقطه برش را داشته باشد و بتوان از هر محلی برش انجام داد. برای این کار، یک رشته حائل و واسطه 
‎(\lr{mask})‎
تعیین می‌شود، که این رشته حائل دارای تعداد ارقام باینری برای ساختار رشته‌های والدین است. 
به عبارت دیگر، طول آن با طول رشته‌های پدر و مادر برابر است وشامل اعداد جفت است. که به صورت تصادفی انتخاب می‌شوند، عدد ‎1‎ معرف نقطه‌ی تعویض و عدد ‎0‎ نشان‌دهنده‌ی عدم تغییر است.
‎\begin{equation*}‎
\text{والد ‎1}‎: ‎x_{1}=[1 0 1 1 0 0 0 1 1 1] \quad \quad \text{فرزند ‎1}‎: ‎x_{1}=[1 0 0 1 0 0 1 0 1 1]‎
‎\end{equation*}‎
‎\begin{equation*}‎
\text{والد ‎2}‎: ‎x_{2}=[0 0 0 1 1 1 1 0 0 0] \quad \quad \text{فرزند ‎2}‎: ‎x_{2}=[0 0 1 1 1 1 0 1 0 0]‎
‎\end{equation*}‎
‎\begin{equation*}‎
‎mask‎: ‎[0 0 1 1 0 0 1 1 0 0]‎
‎\end{equation*}‎







\subsubsection*{عملگر جهش}
عملگر جهش  به مانند عملگر تقاطع، عهده‌دار جنبه‌ی جستجوی الگوریتم ژنتیک است. فلسفه‌ی استفاده از عملگر جهش در الگوریتم ژنتیک، ایجاد تنوع در جمعیت می‌باشد. برای اینکه روی یک بردار مانند 
‎$x_{i}$‎
جهش انجام دهیم، ابتدا باید نرخ تاثیر جهش را تعیین کنیم، با استفاده از این نرخ، تعداد مولفه‌هایی که تحت تاثیر جهش قرار می‌گیرند 
را به صورت 
رابطه‌ی
‎\ref{Mut1}‎ 
 تعیین می‌کنیم: 
‎\begin{equation}‎
\text{تعداد مولفه‌های تحت تاثیر جهش}= \text{نرخ تاثیر جهش} ‎\times x_{i} \text{تعداد متغیر‌های  } 
‎\label{Mut1}‎
‎\end{equation}‎

با به دست آوردن تعداد مولفه‌های تحت تاثیر جهش، به صورت تصادفی مولفه‌هایی را به این تعداد انتخاب می‌کنیم. در حوزه باینری، اگر مولفه ‎(بیت)‎ مورد نظر مقدار یک را داشت به صفر و اگر مقدار صفر داشت به یک، تبدیل می‌کنیم. اما در حوزه اعداد پیوسته، اگر مجموعه مرجع ما 
‎$M=\{X_{min},...,X_{max}\}$‎
باشد و بخواهیم در برداری مانند 
‎$x_{i}$‎
جهش ایجاد کنیم، باید به صورت تصادفی، عددی را در بازه‌ی مشخص‌شده انتخاب کنیم، که برای این کار می‌توانیم از توزیع‌های مختلف تصادفی استفاده کرد که ما در این پایان‌نامه از توزیع تصادفی نرمال به صورت 
‎\ref{Mut2}‎
 استفاده می‌کنیم:
‎\begin{equation}‎
‎x_{i}^{new} \sim N(x_{i},\sigma ^{2})‎
‎\label{Mut2}‎
‎\end{equation}‎
که 
‎$x_{i}$‎
همان برداری است که می‌خواهیم در آن جهش ایجاد کنیم و 
‎$\sigma$‎
انحراف معیاری است که به صورت دلخواه تعیین می‌شود، اما معمولاً متناسب با عرض فضا در نظر گرفته می‌شود، ما در اینجا 
‎$\sigma$‎
را به صورت 
‎$\sigma = \mu (X_{max}‎ - ‎X_{min})$‎
تعیین کرده‌ایم که 
‎$\mu$‎
عددی کوچک است (مثلا ‎0/1)‎. در واقع هرچه قدر 
‎$\sigma$‎
(طول گام) ما بیشتر باشد، جستجوی الگوریتم ژنتیک بیشتر و میزان بهره‌برداری الگوریتم کمتر است. 


\subsubsection*{استراتژی برخورد با محدودیت‌ها‎\LTR‎footnote{Handling Constraints}}‎

بحث دیگری که در الگوریتم ژنتیک وجود دارد، چگونگی برخورد با محدودیت‌های مساله می‌باشد. زیرا عملگر‌های ژنتیک مورد استفاده در الگوریتم، ممکن است باعث تولید نقاط ‎(کروموزوم‌های)‎ غیرموجه شوند. در زیر به بیان استراتژی‌های برخورد با نقاط غیرموجه می‌پردازیم:
‎\begin{enumerate}‎
‎\item‎ استراتژی 
عملگرهای ژنتیک ‎\LTRfootnote{Modifying Genetic Operators Strategy}‎:
یک روش برای جلوگیری از تولید نقاط غیرموجه این است که عملگر ژنتیکی طوری تعریف گردد که پس از عمل بر روی نقاط، نقاط تولید شده نیز موجه باشند. در این حالت یکسری مشکلات وجود دارد؛ مانند، پیدا کردن عملگری که دارای شرایط فوق باشد. پیدا کردن همچین عملگری بسیار دشوار بوده و از مساله به مساله‌ای دیگر متفاوت است. 
‎\item‎ استراتژی
رَدی ‎\LTRfootnote{Rejection Strategy}‎
:
در این روش پس از تولید هر نقطه، آن را از نظر موجه بودن تست کرده و در صورت غیرموجه بودن حذف می‌گردد. این روش بسیار ساده و کارا می‌باشد. 
‎\item‎ استراتژی اصلاحی‎\LTRfootnote{Repairing Strategy}‎ 
:
در این روش به جای اینکه نقاط غیرموجه حذف شوند تبدیل به یک نقطه موجه می‌شوند. این روش نیز مانند روش اول به مساله وابسته بوده و یافتن فرایند اصلاح گاهی بسیار پیچیده می‌باشد. 
‎\item‎ استراتژی جریمه‌ای‎\LTRfootnote{Penalizing Strategy}‎
:
در این روش برخلاف سه روش قبل که از ورود جواب‌های غیرموجه جلوگیری می‌کردند، جواب‌های غیرموجه با احتمال کم امکان حضور می‌یابند. سه روش فوق دارای این اشکال بودند که به هیچ نقطه‌ای بیرون از فضای موجه توجه نمی‌کردند، اما در بعضی از مسائل بهینه‌سازی، جواب‌های غیرموجه درصد زیادی از جمعیت را اشغال می‌کنند. در چنین شرایطی اگر جستجو فقط در ناحیه موجه انجام گیرد شاید یافتن جواب موجه خیلی وقت‌گیر و مشکل باشد. 
‎\end{enumerate}‎

استراتژی جریمه‌ای یکی از متداول‌ترین تکنیک‌های مورد استفاده برای پذیرش جواب‌های غیرموجه می‌باشد؛ که در آن ابتدا محدودیت‌های مساله در نظر گرفته نمی‌شوند، سپس برای هر تخلف از محدودیت‌ها، یک جریمه اختصاص داده می‌شود که این جریمه در تابع هدف قرار می‌گیرد. مساله اصلی،‌ چگونگی انتخاب یک مقدار مناسب برای مقدار جریمه می‌باشد که بتواند در حل مساله کمک نماید. نکته‌ای که در روش جریمه وجود دارد این است که، یک جواب غیرموجه به سادگی حذف نمی‌شود، زیرا ممکن است در ژن‌های آن اطلاعات مفیدی وجود داشته باشد که با اندکی تغییر به جواب بهینه تبدیل شود. 


































\subsection{الگوریتم ‎\lr{NSGA-2}}‎
در طی دو دهه گذشته، به الگوریتم ژنتیک به دلیل پتانسیل بالای آن ها به عنوان یک رویکرد جدید به مسایل بهینه‌سازی چندهدفه که تحت عنوان روش های تکاملی یا بهینه‌سازی چندهدفه ژنتیک شناخته می‌شود، توجه خاصی شده است. ویژگی‌های ذاتی الگوریتم‌های ژنتیک بیانگر دلایل مناسب بودن جستجوی ژنتیک در مسایل بهینه‌سازی چندهدفه هستند. ویژگی‌های اصلی الگوریتم ژنتیک چندجهته بودن و جستجوی سراسری با حفظ جمعیتی از جواب‌های خوب از نسلی به نسلی دیگر است. رویکرد نسل به نسل در زمان بررسی جواب‌های  پارتو‎‎‎ 
مفید است. 

دب و همکاران در سال ‎2002‎ الگوریتم
‎\lr{NSGA-2}‎
را برای رفع کاستی‌های الگوریتم 
‎\lr{NSGA}‎
توسعه دادند. انتقادات اصلی که به الگوریتم 
‎\lr{NSGA}‎
وارد بود عبارت اند از: 
‎\begin{enumerate}‎
‎	\item‎ پیچدگی محاسباتی زیاد در رتبه‌بندی جواب‌های نامغلوب
‎	\item‎ فقدان نخبه‌گرایی
‎	\item‎ نیاز به تعیین پارامتر اشتراک ‎$\sigma_{share}$‎
‎\end{enumerate}‎
در الگوریتم ‎\lr{NSGA-2}‎
برخلاف الگوریتم قبلی که از نخبه‌گرایی فقط در یک بعد استفاده می‌کرد، 
‎\lr{NSGA-2}‎
از یک مکانیسم کاملا روشن برای فراهم آوردن چگالی در بین جواب‌های بهینه پارتو هم استفاده می‌کند. در اغلب مواقع این الگوریتم شباهتی به 
‎\lr{NSGA}‎
ندارد ولی دب و همکاران نام 
‎\lr{NSGA-2}‎
را به دلیل نقطه پیدایش آن یعنی همان 
‎\lr{NSGA}‎
، برای آن حفظ کردند.

قبل از آن‌که روش 
‎\lr{NSGA-2}‎
را شرح دهیم، لازم است تا سه مفهوم زیر بیان شوند:
‎\begin{enumerate}‎
‎\item‎ مرتب‌سازی نامغلوب ‎(\lr{Non-dominated sorting})‎
‎\item‎ 
فاصله ازدحامی 
‎(\lr{Crowding Distance})‎
‎\item‎ عملگر مقایسه‌ای ازدحام ‎(\lr{Crowded-Comparison Operator})‎
‎\end{enumerate}‎

\subsection*{الگوریتم مرتب‌سازی نامغلوب ‎\LTRfootnote{Non-dominated Sorting Algorithm}}‎
در حوزه الگوریتم‌های تکاملی چندهدفه،  تنها لازم است تا بهترین طرح نامغلوب جمعیت یافت شود. این الگوریتم‌ها جمعیت را به دو مجموعه تقسیم می‌کنند: مجموعه نامغلوب و مجموعه مغلوب. البته الگوریتم‌هایی هم وجود دارند که کل جمعیت را به چندین سطح نامغلوب تقسیم می‌نمایند (مانند ‎\lr{NSGA-2})‎ . بهترین جواب‌های نامغلوب، جواب‌های نامغلوب سطح ‎1‎ نامیده می‌شوند. برای یافتن جواب‌های نامغلوب سطح بعدی، معمولاً از یک رویه ساده پیروی می‌شود. زمانی‌که بهترین مجموعه نامغلوب مشخص گردید، آن‌ها را به طور موقت نادیده می‌گیریم. جواب‌های نامغلوب باقیمانده یافت شده، جواب‌های نامغلوب سطح ‎2‎ نامیده می‌شود. به منظور یافتن جواب‌های نامغلوب سطح ‎3‎، همه جواب‌های نامغلوب سطح ‎1‎ و ‎2‎ نادیده گرفته شده و به یافتن جواب‌های نامغلوب جدید پرداخته می‌شود. این رویه ادامه پیدا می‌کند تا این که هر یک از اعضای جمعیت، در یک سطح نامغلوب قرار گیرند. لازم به ذکر است که جواب‌های نامغلوب سطح ‎1‎ از جواب‌های نامغلوب سطح ‎2‎ بهترند و به همین ترتیب برای سطوح بعدی. 
دب و همکاران ‎(2002)‎ یک الگوریتم مرتب‌سازی نامغلوب ارائه کرده‌اند که ما هم از این روش استفاده می‌کنیم. 

در این روش، ابتدا برای هر جواب، دو چیز را محاسبه می‌کنیم: الف) شماره غلبه 
‎$n_{i}$‎
، که همان ‎\textbf{تعداد}‎
جواب‌هایی است که بر جواب ‎\lr{i}‎
غالب هستند. 
ب) 
‎$S_{i}$‎
،
‎\textbf{‎ مجموعه جواب‌هایی}
که ‎\lr{i}‎
بر آن‌ها غالب است. در پایان این رویه، شماره غلبه همه جواب‌های موجود در طرح نامغلوب ابتدایی، صفر خواهد بود. 
حال برای هر یک از این جواب‌ها، (جواب‌ها با 
‎$n_{i}=0$‎
) عدد مجموعه 
‎$S_{i}$‎
آن را بررسی می‌کنیم و شماره غلبه‌اش را به یک کاهش می‌دهیم. در انجام این کار، اگر برای هر عضو ‎\lr{j}‎
، شماره غلبه صفر شود، آن را در یک لیست جداگانه 
‎$P'$‎
قرار می‌دهیم. پس از انجام چنین تعدیلاتی بر روی  
‎$S_{i}$‎
، برای هر ‎\lr{i}‎ با 
‎$n_{i}=0$‎
، همه جواب‌های 
‎$P'$‎
به طرح نامغلوب دوم متعلق خواهند شد. این رویه می‌تواند با هر عضوی از 
‎$P'$‎
ادامه یابد و طرح نامغلوب سوم مشخص گردد. این الگوریتم به صورت زیر است‎:\\‎
‎\textbf{‎گام ‎1:}‎
به ازای هر 
‎$i \in P$‎
و 
‎$n_{i}=0$‎
و
‎$S_{i}=\varnothing $‎
، برای همه 
‎$j \in P$‎
‎$(j \neq i)$‎
گام ‎2‎ را انجام دهید و سپس به گام ‎3‎ بروید. ‎\\‎
‎\textbf{‎گام ‎2:}‎
اگر 
‎$i \preceq j$‎
، به هنگام کنید
‎$S_{‎i‎}=S_{i} \cup \{j\}$‎
، در غیر‌اینصورت اگر
‎$j \preceq i$‎
، قرار دهید
‎$n_{i}=n_{i}‎ + ‎1$\\‎
‎\textbf{‎گام ‎3:}‎
اگر
‎$n_{i}=0$‎
، ‎\lr{i}‎ 
را در اولین طرح نامغلوب 
‎$P_{1}$‎
قرار دهید
(این مجموعه در پاراگراف بالا
‎$P'$‎
می‌باشد)
شمارشگر طرح را برابر یک قرار دهید 
‎$k=1$‎
‎\\‎
‎\textbf{‎گام ‎4:}‎
در حالیکه 
‎$P_{k} \neq \varnothing $‎
، گام‌های زیر را انجام دهید‎:\\‎
‎\textbf{‎گام ‎5:}‎ 
برای مرتب ساختن جواب‌های نامغلوب بعدی قرار دهید 
‎$Q=\varnothing$‎
، برای هر 
‎$i \in P_{k}$‎
و هر 
‎$j \in S_{i}$‎.


‎\textbf{‎گام ‎5‎‎ الف:}
بهنگام کنید 
‎$n_{j}=n_{j}-1$‎

‎\textbf{‎گام ‎5‎‎ ب:}
اگر 
‎$n_{j}=0$‎
، ‎\lr{j}‎
را در
‎\lr{Q}‎
قرار دهید یا 
‎$Q=Q \cup \{i\}$  \\‎
‎\textbf{‎گام ‎6:}‎
قرار دهید 
‎$k=k+1$‎
و
‎$P_{k}=Q$‎
و به گام ‎4‎ بروید.
گام‌های ‎1‎ تا ‎3‎ جواب‌های طرح نامغلوب ابتدایی را می‌یابند. گام‌های ‎4‎ تا ‎6‎ طرح‌های بعدی را می‌یابند. 


\subsection*{فاصله ازدحامی‎\LTRfootnote{Crowding Distance}}‎
این معیار در الگوریتم 
‎\lr{NSGA-2}‎
به عنوان معیار ثانویه، مورد استفاده قرار می‌گیرد. 
در این الگوریتم، برای به دست آوردن تخمینی از چگالی جواب‌های موجود در کنار یک جواب خاص، مانند جواب ‎\lr{i}‎
در جمعیت، یک میانگین فاصله از دو جواب واقع در طرفین جواب ‎\lr{i}‎
، برای هر کدام از ‎\lr{M}‎
تابع هدف، محاسبه می‌کنیم. ‎\\‎
محاسبه فاصله ازدحامی، نیازمند مرتب‌سازی صعودی جمعیت، براساس مقدار هر تابع هدف است. بعد از آن، برای هر تابع هدف، به جواب‌های مرزی (جواب‌هایی با کمترین و بیشترین مقادیر هدف)، مقدارهای بی‌کران تخصیص داده می‌شود. به همه‌ی جواب‌های میانی دیگر، مقدار فاصله برابر با ‎«‎قدر مطلق نرمالایز شده اختلاف مقادیر هدفِ دو جواب همسایه، می‌باشد. این محاسبات برای دیگر توابع هدف نیز تکرار می‌شود. در نهایت، مقدار فاصله ازدحامی به صورت مجموع مقادیر فاصله نقاط به دست می‌آید. ‎\\‎
الگوریتم زیر فرایند محاسبه فاصله ازدحامی برای همه جواب‌ها در یک مجموعه نامغلوب ‎\lr{F}‎
نشان می‌دهد. 
‎\\‎
\textbf{گام ‎1:}‎
قرار می‌دهیم
‎$L=|F|$‎
یا 
‎\lr{L}‎
را برابر طولِ صف
‎\lr{F}‎
در نظر می‌گیریم. سپس برای هر جواب از مجموعه ‎\lr{F}‎
، قرار می‌دهیم 
‎$d_{i}=0$‎
‎\\‎
\textbf{گام ‎2:}‎
برای هر تابع هدف 
‎$(m=1,...,M)$‎
مجموعه 
‎$f_{m}$‎
را به ترتیب نزولی و بر حسب ارزش آن‌ها مرتب می‌کنیم. در واقع بردار اندیس مرتب شده 
‎$I^{m}$‎
که در آن 
‎$I^{m}=Sort(f_{m}‎, ‎>)$‎
را ایجاد می‌کنیم. 
‎\\‎
\textbf{گام ‎3:}‎
از 
‎$m=1$‎
تا 
‎$m=M$‎
یک مقدار بزرگ برای حدود جواب‌ها اختصاص داده و یا 
‎$d_{I_{1}^{m}}=d_{I_{2}^{m}}=\infty$‎
و برای تمام جواب‌های دیگر، 
‎$j=2,3,...,(l-1)$‎
قرار می‌دهیم:
‎\begin{equation}‎
‎\label{multi:crowed}‎
‎d_{I_{j}^{m}} = d_{I_{j}^{m}}‎ + ‎\frac{f_{m}^{(I_{j+1}^{m})}‎ - ‎f_{m}^{(I_{j-1}^{m})}}{f_{m}^{Max}‎ - ‎f_{m}^{Min}}‎
‎\end{equation}‎

اندیس ‎$I_{j}$‎
نمایانگر ‎\lr{j}‎
امین عضو از لیست مرتب شده در گام دوم است. بدین ترتیب برای تمامی توابع هدف از 
‎$I_{1}$‎
تا 
‎$I_{l}$‎
مقدار کمینه و بیشینه از ارزش‌ها نسبت داده می‌شود. قسمت دوم تساوی  
‎\ref{multi:crowed}‎
برابر با میزان اختلاف ارزش توابع هدف، بین دو جواب همسایه طرفین جواب ‎\lr{j}‎
ام است. 
این نکته قابل توجه است که برای هر جواب ‎\lr{i}‎
دو جواب 
‎$(i+1)$‎
و
‎$(i-1)$‎
لزوما به عنوان همسایگان ‎\lr{i}‎
برای تمام توابع هدف نمی‌باشد. 
‎\\‎
پارامتر‌های 
‎$f_{m}^{max}$‎
و
‎$f_{m}^{min}$‎
به ترتیب بیشترین و کمترین ارزش‌های موجود در جمعیت برای 
‎\lr{m}‎
امین هدف می‌باشد؛ سپس برای هر جواب، مقدار فاصله ازدحامی از فرمول
‎\ref{multi:finalcrowd}‎
به دست می‌آید:
‎\begin{equation}‎
‎\label{multi:finalcrowd}‎
‎d_{I_{j}} = \sum_{m=1}^{M} d_{I_{j}^{m}}‎
‎\end{equation}‎

\subsubsection*{عملگر انتخاب مسابقه‌ای ازدحام‎\LTRfootnote{Crowded Tournament Selection Operator}}‎
عملگر انتخاب مسابقه‌ای ازدحام، دو جواب را مقایسه کرده و پیروز مسابقه را مشخص می‌نماید. فرض می‌شود که هر جواب یا راه‌حل ‎\lr{i}‎
دو ویژگی زیر را دارد:
‎\begin{enumerate}‎
‎	\item‎ دارای یک رتبه یا درجه نامغلوب بودن است،‌که آن را با 
‎	$r_{i}$‎
	نشان می‌دهیم
‎	\item‎ دارای یک فاصله ازدحامی است که آن را با 
‎	$d_{i}$‎
	نشان می‌دهیم
‎\end{enumerate}‎

\begin{definition}[عملگر انتخاب مسابقه‌ای ازدحام‎:]‎
	جواب ‎\lr{i}‎ در مسابقه با جواب ‎\lr{j}‎ پیروز می‌شود، اگر و فقط اگر یکی از شرایط زیر برقرار باشد:
‎	\begin{enumerate}‎
	‎	\item‎   
		جواب ‎\lr{i}‎ رتبه بهتری(کوچکتری) داشته باشد: 
	‎	$r_{i}<r_{j}$‎
	‎	\item‎ 
		جواب‌های ‎\lr{i,j}‎ دارای رتبه‌ای یکسان باشند اما جواب ‎\lr{i}‎ از فاصله ازدحامی بهتری(بزرگتری) نسبت به جواب ‎\lr{j}‎ برخوردار است. پس
	‎	$r_{i}=r_{j}$‎
		و 
	‎	$d_{i}>d_{j}$‎
‎	\end{enumerate}‎
‎\end{definition}‎
شرط اول این اطمینان را به وجود می‌آورد که جواب پیروز از درجه نامغلوب بودن بهتری نسبت به رقیب خود برخوردار است. شرط دوم که در هنگام هم رتبه بودن جواب‌ها با آن روبه‌رو خواهیم شد، این اطمینان را به وجود می‌آورد که جواب پیروز از فاصله ازدحامی بزرگتری برخوردار است. 

\subsubsection*{حلقه اصلی}

در این روش ابتدا جمعیت فرزندان 
‎$(Q_{t})$‎
، با استفاده از جمعیت والدین 
‎$P_{t}$‎
ساخته می‌شود.
سپس دو جمعیت والدین و فرزندان با یکدیگر ترکیب شده و جمعیت 
‎$R_{t}$‎
با اندازه 
‎$2N$‎
را ایجاد می‌کنند. سپس با استفاده از الگوریتم مرتب سازی نامغلوب که در بخش قبل توضیح داده شد، تمام جمعیت 
‎$R_{t}$‎
را دسته‌بندی می‌کنیم. در این روش یک مقایسه عمومی در بین اعضای 
‎$R_{t}$‎
انجام می‌شود و پس از ایجاد صف‌ها یا جبهه‌های متفاوت نامغلوب 
(به ترتیب اولویت صف‌ها نسبت به هم)، جمعیت بعدی یکی‌یکی از این صف ها پر می‌شود. پرکردن 
‎$P_{t+1}$‎
با بهترین صف نامغلوب 
‎$(F_{1})$‎
شروع شده و سپس دومین صف نامفلوب 
‎$(F_{2})$‎
و همینطور سومین صف نامغلوب
‎$F_{3}$‎
و الی آخر تا زمانی‌که 
‎$P_{t+1}$‎
پر شود، ادامه می‌یابد.
از آن‌جا‌ که اندازه جمعیت 
‎$R_{t}$‎
(مجموع جمعیت والدین و فرزندان) برابر با 
‎$2N$‎
است، احتمالا بخشی از اعضای آن نتواند در جمعیت جدید 
‎$P_{t+1}$‎
قرار گیرند و باید حذف شوند. در این الگوریتم
(الگوریتم ‎\lr{NSGA-2})‎
برای حذف اعضای باقیمانده از معیار فاصله ازدحامی 
که در بخش قبلی توضیح داده شد، استفاده می‌کنیم.
شکل  ‎\ref{nsgapic}‎ نحوه عمل الگوریتم 
‎\lr{NSGA-2}‎
را نشان می‌دهد.
‎\begin{figure}‎
‎	\begin{center}‎
	‎	\includegraphics[scale=1.2]{NSGApic2.pdf}‎
‎	\end{center}‎
	\caption{نمایشی از نحوه عملکرد الگوریتم ‎\lr{NSGA-2}}‎
‎	\label{nsgapic}‎
‎\end{figure}‎

در ادامه، روش ‎\lr{NSGA-2}‎
را به اختصار آورده‌ایم:
‎\\‎
\textbf{گام ‎1}‎: 
جمعیت فرزندان و والدین را با یکدیگر ترکیب کرده و 
‎$R_{t}$‎
را می‌سازیم:
‎\begin{equation*}‎
‎R_{t}=P_{t} \bigcup Q_{t}‎
‎\end{equation*}‎
سپس 
‎$R_{t}$‎
را با استفاده از الگوریتم مرتب‌سازی نامغلوب به صفوف ‎(جبهه‌های)‎ 
‎$F_{i}$‎
که 
‎$i=1,2,...,etc;$‎
دسته‌بندی می‌کنیم. 

\textbf{گام ‎2}‎:
قرار می‌دهیم، 
‎$i=1,P_{t+1}=\phi$‎
، سپس تا زمانی که 
‎$|P_{t+1}|‎ + ‎|F_{i}| < N$‎
برقرار است، عملیات زیر را تکرار می‌کنیم:
‎\begin{equation*}‎
\{ ‎P_{t+1} = P_{t+1} \bigcup F_{i} \quad‎, ‎i=i+1‎ \}
‎\end{equation*}‎

\textbf{گام ‎3}‎:
فاصله ازدحامی را برای 
‎$(N-|P_{t+1}|)$‎
از جواب‌های 
‎$F_{i}$‎
تعیین می‌کنیم. 

\textbf{گام ‎4}‎:
جمعیت فرزندان 
‎$Q_{t+1}$‎
را از 
‎$P_{t+1}$‎
با استفاده از الگوریتم انتخاب مسابقه‌ای ازدحام (قبلا توضیح داده شده است) و عملگرهای تقاطع و جهش ایجاد می‌کنیم. 
‎\\‎

گام اول از این الگوریتم به یک مرتب‌سازی نامغلوب از جمعیت با اندازه ‎\lr{2N}‎
نیاز دارد. این عمل حداکثر از درجه 
‎$O(MN^{2})$‎
خواهد بود. مرتب‌سازی در گام سوم به محاسبه فاصله ازدحامی نیازمند است که برای تمام اعضای صف 
‎\lr{i}‎
انجام می‌شود. مسابقه انتخابی در گام چهارم به محاسبات فاصله ازدحام برای تمام ‎\lr{N}‎
عضو
(اندازه جمعیت 
‎$P_{t+1}$)‎
نیاز دارد. پس این دو مرحله از الگوریتم به 
‎$O(MN logN)$‎
محاسبه نیاز دارد. بنابراین در حالت کلی پیچیدگی محاسباتی الگوریتم از درجه 
‎$O(MN^{2})$‎
خواهد بود.
\subsection*{روش برخورد با محدودیت در الگوریتم ‎\lr{NSGA-2}}‎

\subsubsection*{روش مسابقه محدودیت}
در بخش‌های قبل در مورد استراتژی‌های برخورد با محدودیت، مطالبی گفته شد. اما در روش ‎\lr{NSGA-2}‎
از روش ‎«‎مسابقه محدودیت‎» \LTRfootnote{Constraned Tournament Method}‎
برای برخورد با محدودیت استفاده می‌شود. 
در گذشته، دب و همکاران، یک روش برای برخورد با محدودیت بدون پارامتر جریمه، جهت حل مسایل بهینه‌سازی تک هدفه، پیاده‌سازی کرده‌اند. مطالعات آن ها  نشان داده که یک الگوریتم مبتنی بر  انتخاب مسابقه‌ای  برای برخورد با محدودیت، بسیار بهتر از دیگر روش‌هاست.​ آن‌ها روشی مشابهی برای حل مسایل بهینه‌سازی چندهدفه با محدودیت، معرفی کرده‌اند.

در این شیوه، برای ارضا محدودیت‌ها از یک عملگر انتخاب مسابقه‌ای دودویی استفاده می‌شود که در آن دو جواب از جمعیت انتخاب شده و جواب بهتر به عنوان برنده برگزیده می‌شود. هنگامی‌که بحث محدودیت‌ها پیش می‌آید، هر جوابی یا موجه است یا ناموجه. بنابراین سه حالت کلی در یک مسابقه دودویی پیش می‌آید:
‎\begin{enumerate}‎
‎\item‎ هردو جواب موجه‌اند.
‎\item‎ یکی از جواب‌ها موجه و دیگری ناموجه است. 
‎\item‎ هر دو جواب ناموجه‌اند. 
‎\end{enumerate}‎
در بهینه‌سازی تک هدفه، برای هر حالت بالا، قواعد زیر را به کار می‌بریم. 
‎\begin{itemize}‎
‎\item‎ حالت ‎1‎: جوابی با بهترین مقدار هدف انتخاب می‌شود.
‎\item‎ حالت ‎2‎: جواب شدنی برگزیده می‌شود.
‎\item‎ حالت ‎3‎: جوابی که نقض محدودیت کوچکتری دارد انتخاب می‌شود.
‎\end{itemize}‎
در بهینه‌سازی چندهدفه، حالت‌های ‎2‎ و ‎3‎ را می‌توان به همین صورت به کار برد. حالت ‎1‎ نیز با استفاده از ‎«‎عملگر انتخاب مسابقه‌ای ازدحام‎»‎ که قبلا بیان شد، مشکل چند‎‏هدفه بودنش حل می‌شود. تنها لازم است که تغییری ساده بر روی تعریف ‎«غلبه»‎ بین دو جواب 
‎\lr{i}‎
و
‎\lr{j}‎
انجام شود. 

\begin{definition}[غلبه در محدودیت‎\LTRfootnote{Constrained-Dominate}]‎
جواب 
‎$x_{i}$‎
بر جواب
‎$x_{j}$‎
‏‎«‎غلبه در محدودیت‎»‎ دارد، هرگاه یکی از شرایط زیر برقرار باشد:
‎\begin{enumerate}‎
‎\item‎ جواب ‎$x_{i}$‎
موجه و جواب
‎$x_{j}$‎
ناموجه باشد.
‎\item‎ 
جواب‌های 
‎$x_{i}$‎
و
‎$x_{j}$‎
هر دو موجه‌اند و جواب 
‎$x_{i}$‎
به جواب 
‎$x_{j}$‎ 
با همان تعریف سابق از غلبه که در تعریف 
‎\ref{dom}‎
آورده شده، غالب است.
‎\end{enumerate}‎
‎\end{definition}‎

می‌توانیم همان روال طبقه‌بندی نامغلوب که در بخش قبلی توضیح داده شد را برای دسته‌بندی جمعیت در سطوح مختلف از نامغلوب بودن به کار گیریم. فقط باید تعریف بالا را به جای تعریف قبلی غلبه، به کار ببریم.  با این تعریف، همه جواب‌های موجه طبق سطح نامغلوب‌شان و  براساس مقادیر تابع هدف رتبه‌بندی می‌شوند. ​با این حال، از میان دو جواب ناموجه، جواب با تخطی محدودیت کوچک‌تر، رتبه بهتری دارد. ​






































